{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tf_dqn_agent import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape:  (8,)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2')\n",
    "# env.seed(42)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "print('Number of actions: ', env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00494251  1.4087303   0.5006124  -0.09732987 -0.0057204  -0.11339606\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(state_size=8, action_size=4)\n",
    "\n",
    "# watch an untrained agent\n",
    "state = env.reset()\n",
    "for j in range(200):\n",
    "    state = np.reshape(state, [1, 8])\n",
    "    action = agent.act(state)\n",
    "    env.render()\n",
    "    time.sleep(0.01)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0/5000, score: -78.67214089406838, after time: 149\n",
      "episode: 1/5000, score: -66.46713050919372, after time: 999\n",
      "episode: 2/5000, score: -48.59214115331608, after time: 82\n",
      "episode: 3/5000, score: -41.67755062600905, after time: 84\n",
      "episode: 4/5000, score: -32.91917036823874, after time: 92\n",
      "episode: 5/5000, score: -299.1264334419036, after time: 206\n",
      "episode: 6/5000, score: -232.5040359155132, after time: 658\n",
      "episode: 7/5000, score: -139.85427234693515, after time: 136\n",
      "episode: 8/5000, score: -61.94395226820352, after time: 155\n",
      "episode: 9/5000, score: -22.008313815620895, after time: 286\n",
      "episode: 10/5000, score: -51.79911894871987, after time: 172\n",
      "episode: 11/5000, score: -6.243241683934897, after time: 167\n",
      "episode: 12/5000, score: 8.603503515483068, after time: 999\n",
      "episode: 13/5000, score: 119.51037093428216, after time: 999\n",
      "episode: 14/5000, score: 79.21356983386528, after time: 999\n",
      "episode: 15/5000, score: 60.748459427626464, after time: 999\n",
      "episode: 16/5000, score: -110.58721365199062, after time: 999\n",
      "episode: 17/5000, score: -13.724556515769436, after time: 121\n",
      "episode: 18/5000, score: -24.222540210074143, after time: 88\n",
      "episode: 19/5000, score: -39.255789129077186, after time: 80\n",
      "episode: 20/5000, score: -195.55884426105075, after time: 431\n",
      "episode: 21/5000, score: -2.544577481751057, after time: 999\n",
      "episode: 22/5000, score: -202.07465330080834, after time: 222\n",
      "episode: 23/5000, score: -232.60382036545775, after time: 514\n",
      "episode: 24/5000, score: -9.841045966140143, after time: 101\n",
      "episode: 25/5000, score: -132.98464246629598, after time: 908\n",
      "episode: 26/5000, score: -135.29519912267034, after time: 186\n",
      "episode: 27/5000, score: -124.21051337849508, after time: 123\n",
      "episode: 28/5000, score: -97.517107776015, after time: 410\n",
      "episode: 29/5000, score: 82.66834585283884, after time: 999\n",
      "episode: 30/5000, score: 11.24234511714102, after time: 999\n",
      "episode: 31/5000, score: 81.24172876342604, after time: 999\n",
      "episode: 32/5000, score: -152.842557986484, after time: 370\n",
      "episode: 33/5000, score: 32.91783959569829, after time: 999\n",
      "episode: 34/5000, score: -1.9701500471631448, after time: 131\n",
      "episode: 35/5000, score: -330.7783712848312, after time: 203\n",
      "episode: 36/5000, score: 158.00928403780907, after time: 999\n",
      "episode: 37/5000, score: -204.5876370848009, after time: 151\n",
      "episode: 38/5000, score: -27.1584256146797, after time: 117\n",
      "episode: 39/5000, score: 153.2429909667718, after time: 999\n",
      "episode: 40/5000, score: 23.610964231775057, after time: 135\n",
      "episode: 41/5000, score: -327.66180982405604, after time: 282\n",
      "episode: 42/5000, score: -79.32850369567868, after time: 176\n",
      "episode: 43/5000, score: -116.24485162004527, after time: 177\n",
      "episode: 44/5000, score: -18.02843574000093, after time: 113\n",
      "episode: 45/5000, score: 13.857501580289536, after time: 999\n",
      "episode: 46/5000, score: -122.63214281508965, after time: 123\n",
      "episode: 47/5000, score: -22.519730877983207, after time: 269\n",
      "episode: 48/5000, score: -69.7366970429046, after time: 103\n",
      "episode: 49/5000, score: 4.7397348011885185, after time: 80\n",
      "episode: 50/5000, score: 36.68931242193102, after time: 999\n",
      "episode: 51/5000, score: 72.01761752237604, after time: 999\n",
      "episode: 52/5000, score: 120.19337323821468, after time: 999\n",
      "episode: 53/5000, score: 58.405888638781434, after time: 999\n",
      "episode: 54/5000, score: 29.407554355130912, after time: 999\n",
      "episode: 55/5000, score: -334.7581220863918, after time: 352\n",
      "episode: 56/5000, score: 126.05207036709271, after time: 999\n",
      "episode: 57/5000, score: -216.50293932342112, after time: 638\n",
      "episode: 58/5000, score: 79.66650792627513, after time: 999\n",
      "episode: 59/5000, score: -47.813929256979094, after time: 107\n",
      "episode: 60/5000, score: 16.887512631259934, after time: 999\n",
      "episode: 61/5000, score: 28.059990213807993, after time: 999\n",
      "episode: 62/5000, score: -21.021432983839972, after time: 80\n",
      "episode: 63/5000, score: 9.270783422019605, after time: 95\n",
      "episode: 64/5000, score: -387.7244835568306, after time: 792\n",
      "episode: 65/5000, score: -199.95119770730605, after time: 214\n",
      "episode: 66/5000, score: 146.9952835030662, after time: 999\n",
      "episode: 67/5000, score: -23.343829479239634, after time: 999\n",
      "episode: 68/5000, score: 66.26590541231776, after time: 999\n",
      "episode: 69/5000, score: 133.19732943103713, after time: 999\n",
      "episode: 70/5000, score: 38.12419674745773, after time: 999\n",
      "episode: 71/5000, score: 121.07988391093023, after time: 999\n",
      "episode: 72/5000, score: 108.756420726082, after time: 999\n",
      "episode: 73/5000, score: -57.95107261100501, after time: 355\n",
      "episode: 74/5000, score: -220.32691210733094, after time: 191\n",
      "episode: 75/5000, score: -196.43943991161052, after time: 405\n",
      "episode: 76/5000, score: 123.7826581987779, after time: 999\n",
      "episode: 77/5000, score: -1.4466832725557666, after time: 999\n",
      "episode: 78/5000, score: -271.88718123301464, after time: 468\n",
      "episode: 79/5000, score: 42.542447766691566, after time: 112\n",
      "episode: 80/5000, score: 19.53549250449023, after time: 999\n",
      "episode: 81/5000, score: 66.38173823023514, after time: 999\n",
      "episode: 82/5000, score: -73.96890805556153, after time: 999\n",
      "episode: 83/5000, score: -9.255355240578893, after time: 104\n",
      "episode: 84/5000, score: -59.64409864622618, after time: 999\n",
      "episode: 85/5000, score: -14.773640965126885, after time: 999\n",
      "episode: 86/5000, score: 88.73721566861977, after time: 999\n",
      "episode: 87/5000, score: 97.4103375532278, after time: 999\n",
      "episode: 88/5000, score: 163.4798708561848, after time: 999\n",
      "episode: 89/5000, score: 62.30870344551366, after time: 999\n",
      "episode: 90/5000, score: -267.9751542684357, after time: 206\n",
      "episode: 91/5000, score: -68.29647536460278, after time: 999\n",
      "episode: 92/5000, score: -38.83263784727869, after time: 999\n",
      "episode: 93/5000, score: -171.41234938587667, after time: 214\n",
      "episode: 94/5000, score: 127.99059783030971, after time: 999\n",
      "episode: 95/5000, score: -32.48774681610645, after time: 84\n",
      "episode: 96/5000, score: 98.80625855065097, after time: 999\n",
      "episode: 97/5000, score: -240.236012495659, after time: 584\n",
      "episode: 98/5000, score: -126.13273627749996, after time: 216\n",
      "episode: 99/5000, score: -70.25009080340617, after time: 999\n",
      "episode: 100/5000, score: 279.5330943599771, after time: 589\n",
      "episode: 101/5000, score: 111.37086070924154, after time: 999\n",
      "episode: 102/5000, score: 58.824598721811235, after time: 999\n",
      "episode: 103/5000, score: 60.34311189085318, after time: 999\n",
      "episode: 104/5000, score: -154.57821851975746, after time: 490\n",
      "episode: 105/5000, score: -40.927189001133826, after time: 113\n",
      "episode: 106/5000, score: -110.97663660447009, after time: 128\n",
      "episode: 107/5000, score: -43.59913806385052, after time: 999\n",
      "episode: 108/5000, score: 17.412970794441648, after time: 119\n",
      "episode: 109/5000, score: -328.537186593431, after time: 659\n",
      "episode: 110/5000, score: 111.14446100571567, after time: 999\n",
      "episode: 111/5000, score: 83.86576980610577, after time: 999\n",
      "episode: 112/5000, score: 125.7099941777508, after time: 999\n",
      "episode: 113/5000, score: -171.4380688626726, after time: 245\n",
      "episode: 114/5000, score: 44.30075287232823, after time: 999\n",
      "episode: 115/5000, score: 109.91048434989513, after time: 999\n",
      "episode: 116/5000, score: -1105.9850772158034, after time: 300\n",
      "episode: 117/5000, score: -9.973656106873122, after time: 112\n",
      "episode: 118/5000, score: -64.63955553855907, after time: 78\n",
      "episode: 119/5000, score: 23.24249197376232, after time: 999\n",
      "episode: 120/5000, score: -482.2054741013784, after time: 303\n",
      "episode: 121/5000, score: -114.29163614802218, after time: 338\n",
      "episode: 122/5000, score: 194.28736745068605, after time: 917\n",
      "episode: 123/5000, score: 187.86233692475628, after time: 617\n",
      "episode: 124/5000, score: -89.41936671367492, after time: 145\n",
      "episode: 125/5000, score: 115.48594001717595, after time: 999\n",
      "episode: 126/5000, score: 128.85633677680048, after time: 999\n",
      "episode: 127/5000, score: -148.0593793425622, after time: 311\n",
      "episode: 128/5000, score: -150.3238167616229, after time: 190\n",
      "episode: 129/5000, score: 218.92176050126247, after time: 402\n",
      "episode: 130/5000, score: -135.98387699283012, after time: 113\n",
      "episode: 131/5000, score: -224.37652304166755, after time: 214\n",
      "episode: 132/5000, score: 64.98851002372818, after time: 999\n",
      "episode: 133/5000, score: -6.886233666814192, after time: 453\n",
      "episode: 134/5000, score: -61.080434567608336, after time: 355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 135/5000, score: -257.00312017139413, after time: 117\n",
      "episode: 136/5000, score: -242.87883583590127, after time: 119\n",
      "episode: 137/5000, score: -279.31467401063276, after time: 652\n",
      "episode: 138/5000, score: 70.44119291066778, after time: 999\n",
      "episode: 139/5000, score: -72.42140052707201, after time: 438\n",
      "episode: 140/5000, score: -6.698041469066425, after time: 168\n",
      "episode: 141/5000, score: -268.25866973696714, after time: 140\n",
      "episode: 142/5000, score: -69.12416184040836, after time: 81\n",
      "episode: 143/5000, score: -192.06504296692162, after time: 129\n",
      "episode: 144/5000, score: -159.75950240724336, after time: 106\n",
      "episode: 145/5000, score: -23.50677811770433, after time: 761\n",
      "episode: 146/5000, score: -68.41211210100222, after time: 408\n",
      "episode: 147/5000, score: -71.81509739979896, after time: 175\n",
      "episode: 148/5000, score: -266.4253426657855, after time: 224\n",
      "episode: 149/5000, score: -87.51676697696075, after time: 246\n",
      "episode: 150/5000, score: -366.3585067569401, after time: 244\n",
      "episode: 151/5000, score: -237.9965465736682, after time: 213\n",
      "episode: 152/5000, score: -15.04624553948048, after time: 139\n",
      "episode: 153/5000, score: -258.3778813795633, after time: 320\n",
      "episode: 154/5000, score: -68.89627405432566, after time: 99\n",
      "episode: 155/5000, score: 28.287694927303303, after time: 999\n",
      "episode: 156/5000, score: -173.15686659030771, after time: 99\n",
      "episode: 157/5000, score: -17.189374140811935, after time: 465\n",
      "episode: 158/5000, score: -78.20142417687666, after time: 105\n",
      "episode: 159/5000, score: 208.18370927493496, after time: 341\n",
      "episode: 160/5000, score: -69.31028402405015, after time: 182\n",
      "episode: 161/5000, score: 220.7783499913544, after time: 369\n",
      "episode: 162/5000, score: -42.70663875082148, after time: 112\n",
      "episode: 163/5000, score: -455.1113714916782, after time: 68\n",
      "episode: 164/5000, score: -517.1243299608287, after time: 86\n",
      "episode: 165/5000, score: -464.03698136006506, after time: 71\n",
      "episode: 166/5000, score: -347.4607531935968, after time: 94\n",
      "episode: 167/5000, score: -356.366956018563, after time: 115\n",
      "episode: 168/5000, score: -197.56846289944937, after time: 336\n",
      "episode: 169/5000, score: -247.2549023432526, after time: 154\n",
      "episode: 170/5000, score: -142.02813153301292, after time: 67\n",
      "episode: 171/5000, score: -242.02934083322432, after time: 92\n",
      "episode: 172/5000, score: -332.550464636621, after time: 100\n",
      "episode: 173/5000, score: -178.09699322614375, after time: 100\n",
      "episode: 174/5000, score: -332.9001688099878, after time: 160\n",
      "episode: 175/5000, score: -246.2128138924824, after time: 131\n",
      "episode: 176/5000, score: -125.75166345538241, after time: 143\n",
      "episode: 177/5000, score: -62.60725871890175, after time: 999\n",
      "episode: 178/5000, score: 69.6078488187086, after time: 999\n",
      "episode: 179/5000, score: -341.6892115147782, after time: 225\n",
      "episode: 180/5000, score: -137.78601558622046, after time: 128\n",
      "episode: 181/5000, score: -52.596217000508645, after time: 121\n",
      "episode: 182/5000, score: -368.3554169979678, after time: 84\n",
      "episode: 183/5000, score: -246.10161801851518, after time: 122\n",
      "episode: 184/5000, score: -502.6043263581162, after time: 104\n",
      "episode: 185/5000, score: -134.26949515849088, after time: 191\n",
      "episode: 186/5000, score: -252.41295607151667, after time: 146\n",
      "episode: 187/5000, score: -94.5067330461769, after time: 170\n",
      "episode: 188/5000, score: -123.84426652099651, after time: 158\n",
      "episode: 189/5000, score: -119.94654176533317, after time: 137\n",
      "episode: 190/5000, score: -208.9758917622139, after time: 204\n",
      "episode: 191/5000, score: -33.99425268067078, after time: 346\n",
      "episode: 192/5000, score: 97.56281268159324, after time: 999\n",
      "episode: 193/5000, score: 118.87195349897219, after time: 999\n",
      "episode: 194/5000, score: -62.680395555255345, after time: 999\n",
      "episode: 195/5000, score: -7.480887947891924, after time: 999\n",
      "episode: 196/5000, score: -135.82920985191132, after time: 991\n",
      "episode: 197/5000, score: 200.96091665222636, after time: 435\n",
      "episode: 198/5000, score: 113.12736542852764, after time: 999\n",
      "episode: 199/5000, score: 117.56947089717232, after time: 999\n",
      "episode: 200/5000, score: 26.30922327044131, after time: 999\n",
      "episode: 201/5000, score: -19.363850965682573, after time: 64\n",
      "episode: 202/5000, score: -43.37659130003705, after time: 75\n",
      "episode: 203/5000, score: -47.232835439418224, after time: 172\n",
      "episode: 204/5000, score: -7.395950441115133, after time: 91\n",
      "episode: 205/5000, score: -77.34662377544245, after time: 110\n",
      "episode: 206/5000, score: -113.16891236406809, after time: 999\n",
      "episode: 207/5000, score: -25.628147190278934, after time: 999\n",
      "episode: 208/5000, score: 0.02719158111146336, after time: 999\n",
      "episode: 209/5000, score: 255.1759945927389, after time: 252\n",
      "episode: 210/5000, score: 3.9827372909731906, after time: 133\n",
      "episode: 211/5000, score: 201.7828186386223, after time: 967\n",
      "episode: 212/5000, score: 198.08984782014628, after time: 746\n",
      "episode: 213/5000, score: 39.403476418795435, after time: 359\n",
      "episode: 214/5000, score: 211.78089465875138, after time: 970\n",
      "episode: 215/5000, score: 158.0958939044629, after time: 999\n",
      "episode: 216/5000, score: 46.88369254522817, after time: 999\n",
      "episode: 217/5000, score: -26.8355061015494, after time: 999\n",
      "episode: 218/5000, score: 237.66175250698385, after time: 515\n",
      "episode: 219/5000, score: -599.0044145167641, after time: 176\n",
      "episode: 220/5000, score: 200.3465069554901, after time: 666\n",
      "episode: 221/5000, score: 203.30019429243117, after time: 847\n",
      "episode: 222/5000, score: -110.36284641819826, after time: 499\n",
      "episode: 223/5000, score: 3.0574121181634304, after time: 999\n",
      "episode: 224/5000, score: -147.48496452891334, after time: 999\n",
      "episode: 225/5000, score: -42.16773515312394, after time: 999\n",
      "episode: 226/5000, score: -17.553010832730706, after time: 495\n",
      "episode: 227/5000, score: 243.17829831465252, after time: 666\n",
      "episode: 228/5000, score: 72.88289443690888, after time: 999\n",
      "episode: 229/5000, score: -76.99188566907969, after time: 788\n",
      "episode: 230/5000, score: -163.70685456417243, after time: 163\n",
      "episode: 231/5000, score: -10.878854270813179, after time: 134\n",
      "episode: 232/5000, score: 38.46863638613232, after time: 999\n",
      "episode: 233/5000, score: 294.44702301617986, after time: 316\n",
      "episode: 234/5000, score: 165.6690801517056, after time: 990\n",
      "episode: 235/5000, score: 186.27678049042783, after time: 520\n",
      "episode: 236/5000, score: 13.675303525500937, after time: 135\n",
      "episode: 237/5000, score: 30.16097086279666, after time: 149\n",
      "episode: 238/5000, score: 17.004754076931633, after time: 126\n",
      "episode: 239/5000, score: 24.451320637150815, after time: 162\n",
      "episode: 240/5000, score: -12.557096943806755, after time: 363\n",
      "episode: 241/5000, score: -113.52251466346013, after time: 490\n",
      "episode: 242/5000, score: 151.08769844665687, after time: 723\n",
      "episode: 243/5000, score: -55.96436884781109, after time: 88\n",
      "episode: 244/5000, score: -30.519002547490487, after time: 126\n",
      "episode: 245/5000, score: 5.026252761603075, after time: 253\n",
      "episode: 246/5000, score: -31.714748459132977, after time: 77\n",
      "episode: 247/5000, score: -90.40249521065921, after time: 862\n",
      "episode: 248/5000, score: -598.4528170065905, after time: 291\n",
      "episode: 249/5000, score: -94.55296875062336, after time: 609\n",
      "episode: 250/5000, score: -54.05524881577218, after time: 107\n",
      "episode: 251/5000, score: -305.56890983317123, after time: 407\n",
      "episode: 252/5000, score: -38.5001266979631, after time: 253\n",
      "episode: 253/5000, score: -36.042300388518754, after time: 144\n",
      "episode: 254/5000, score: -54.71806377833366, after time: 709\n",
      "episode: 255/5000, score: -56.00522891075099, after time: 84\n",
      "episode: 256/5000, score: -73.87783780764744, after time: 464\n",
      "episode: 257/5000, score: 108.13690710471398, after time: 999\n",
      "episode: 258/5000, score: -46.86035725446021, after time: 72\n",
      "episode: 259/5000, score: -248.26443222853115, after time: 966\n",
      "episode: 260/5000, score: 13.630105232360311, after time: 999\n",
      "episode: 261/5000, score: -13.805004334890441, after time: 351\n",
      "episode: 262/5000, score: 199.90164813810077, after time: 786\n",
      "episode: 263/5000, score: 31.016176766588586, after time: 131\n",
      "episode: 264/5000, score: 193.24219157870482, after time: 871\n",
      "episode: 265/5000, score: 5.162699240253161, after time: 153\n",
      "episode: 266/5000, score: 167.8151093868055, after time: 507\n",
      "episode: 267/5000, score: -211.50256388965693, after time: 775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 268/5000, score: 125.86665894225716, after time: 999\n",
      "episode: 269/5000, score: -120.85772730998865, after time: 999\n",
      "episode: 270/5000, score: -65.91157622816812, after time: 307\n",
      "episode: 271/5000, score: -12.85577588874986, after time: 515\n",
      "episode: 272/5000, score: 147.5629922708764, after time: 999\n",
      "episode: 273/5000, score: -58.885608652663734, after time: 277\n",
      "episode: 274/5000, score: -36.46066298213826, after time: 89\n",
      "episode: 275/5000, score: -72.71220398656776, after time: 74\n",
      "episode: 276/5000, score: -40.259575826099606, after time: 74\n",
      "episode: 277/5000, score: -200.86777239444262, after time: 110\n",
      "episode: 278/5000, score: -43.38839708336019, after time: 89\n",
      "episode: 279/5000, score: -207.30458366900905, after time: 349\n",
      "episode: 280/5000, score: -594.714286364837, after time: 577\n",
      "episode: 281/5000, score: -267.3133586155896, after time: 391\n",
      "episode: 282/5000, score: 29.350246693466573, after time: 502\n",
      "episode: 283/5000, score: 209.8852030661699, after time: 596\n",
      "episode: 284/5000, score: -311.0646907573946, after time: 735\n",
      "episode: 285/5000, score: 170.0686655100905, after time: 960\n",
      "episode: 286/5000, score: -61.27253735649329, after time: 999\n",
      "episode: 287/5000, score: -68.07195541850892, after time: 999\n",
      "episode: 288/5000, score: -7.374297230543021, after time: 110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a6ca753f6e8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AI/deep-reinforcement-learning/dqn/exercise/tf_dqn_agent.py\u001b[0m in \u001b[0;36mreplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mfuture_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mfuture_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_target_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    871\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/tensorflow-2/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episodes = 5000\n",
    "scores_window = deque(maxlen=100)\n",
    "scores = []\n",
    "for e in range(episodes + 1):\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, 8])\n",
    "    score = 0\n",
    "    for t in range(1000):\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.reshape(next_state, [1, 8])\n",
    "        agent.step(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        score += reward\n",
    "        if done:\n",
    "            print(\"episode: {}/{}, score: {}, after time: {}\".format(e, episodes, score, t))\n",
    "            break\n",
    "        \n",
    "        if ((t+1)% 4) == 0:\n",
    "            if agent.memory.__len__()>=64:\n",
    "                agent.replay()\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "    \n",
    "    scores.append(score)\n",
    "    scores_window.append(score)\n",
    "    if e+1 % 50 == 0:\n",
    "        mean_score = np.mean(scores_window)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(e, mean_score))\n",
    "        if mean_score>=-50.0:\n",
    "            agent.qnetwork.save_weights(\"weights_{}.h5\".format(e))\n",
    "            break\n",
    "    \n",
    "    if e %200 == 0:\n",
    "        agent.qnetwork.save_weights(\"weights_{}.h5\".format(e))\n",
    "        \n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "for j in range(300):\n",
    "    state = np.reshape(state, [1, 8])\n",
    "    action = agent.act(state)\n",
    "    env.render()\n",
    "    time.sleep(0.01)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break \n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
